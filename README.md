# Projeto de DetecÃ§Ã£o de SemÃ¡foros e Placas de Pare com YOLOv5

Este repositÃ³rio contÃ©m o cÃ³digo e os resultados do treinamento de um modelo YOLOv5 para detectar especificamente semÃ¡foros (`traffic light`) e placas de pare (`stop sign`).

## ğŸ¯ Objetivo

O objetivo principal deste projeto foi realizar o fine-tuning de um modelo YOLOv5s prÃ©-treinado para identificar apenas duas classes (`traffic light` e `stop sign`) a partir de um subset do dataset COCO128. O projeto abordou os desafios da configuraÃ§Ã£o do ambiente, preparaÃ§Ã£o dos dados e treinamento da rede para um domÃ­nio especÃ­fico.

## âš™ï¸ Tecnologias Utilizadas

* **Python**
* **PyTorch**
* **YOLOv5** (implementaÃ§Ã£o Ultralytics)
* **Anaconda/Miniconda** (para gerenciamento de ambiente)
* **Git** e **GitHub** (para controle de versÃ£o)
* **Google Colab** (ambiente de desenvolvimento e treinamento, conforme notebook)

## ğŸ“Š Dataset

Para este projeto, foi utilizado um subset do dataset COCO128, que contÃ©m um nÃºmero limitado de instÃ¢ncias das classes alvo.

* **Nome:** COCO128
* **Classes Alvo:**
    * `traffic light` (remapeado para ID: 0)
    * `stop sign` (remapeado para ID: 1)
* **ObservaÃ§Ã£o:** Devido ao tamanho limitado do dataset (128 imagens no total, com poucas instÃ¢ncias das classes alvo), os resultados de desempenho foram iniciais e indicam a necessidade de um dataset maior para um modelo robusto.

## ğŸš€ Como Executar o Projeto

Para replicar o treinamento ou utilizar o modelo:

1.  **Clone este repositÃ³rio:**
    ```bash
    git clone [https://github.com/danielvlemos/treinamento_rede_yolo.git](https://github.com/danielvlemos/treinamento_rede_yolo.git)
    cd treinamento_rede_yolo
    ```

2.  **Crie e ative o ambiente virtual (opcional, mas recomendado):**
    ```bash
    # Com conda
    conda create -n yolov5_env python=3.9
    conda activate yolov5_env

    # Ou com venv
    python -m venv venv
    .\venv\Scripts\activate # No Windows
    source venv/bin/activate # No Linux/macOS
    ```

3.  **Instale as dependÃªncias:**
    ```bash
    pip install -r requirements.txt
    ```
    *Se vocÃª nÃ£o tem um `requirements.txt`, pode criar um com `pip freeze > requirements.txt` no seu ambiente com as libs instaladas, ou listar as principais:*
    ```
    torch
    torchvision
    ultralytics
    matplotlib
    numpy
    pandas
    tqdm
    PyYAML
    seaborn
    ```

4.  **Estrutura de Pastas (Esperada):**
    Certifique-se de que a estrutura de pastas para os dados esteja conforme o esperado pelo YOLOv5 e configurada no arquivo `data.yaml`.
    ```
    .
    â”œâ”€â”€ Projeto_de_criaÃ§Ã£o_de_uma_base_de_dados_e_treinamento_da_rede_YOLO.ipynb
    â”œâ”€â”€ data.yaml
    â”œâ”€â”€ requirements.txt
    â”œâ”€â”€ runs/ # Gerado apÃ³s o treinamento (ignoradas pelo .gitignore)
    â”œâ”€â”€ yolov5/ # Pasta do YOLOv5 (se vocÃª a clonou aqui ou fez download)
    â””â”€â”€ README.md
    â””â”€â”€ .gitignore
    ```

5.  **Treinamento do Modelo:**
    VocÃª pode executar o treinamento utilizando o notebook Jupyter `Projeto_de_criaÃ§Ã£o_de_uma_base_de_dados_e_treinamento_da_rede_YOLO.ipynb` em um ambiente como o Google Colab ou localmente.
    Alternativamente, o comando de treinamento via terminal seria similar a:
    ```bash
    python yolov5/train.py --img 640 --batch 16 --epochs 100 --data data.yaml --weights yolov5s.pt --name traffic_signs_run
    ```
    (Ajuste os caminhos e parÃ¢metros conforme sua configuraÃ§Ã£o.)

## ğŸ“ˆ Resultados do Treinamento

O treinamento foi realizado por 100 Ã©pocas. Os resultados de validaÃ§Ã£o iniciais sÃ£o os seguintes:

| Class             | Images | Instances | P         | R         | mAP50     | mAP50-95  |
| :---------------- | :----- | :-------- | :-------- | :-------- | :-------- | :-------- |
| **all** | 128    | 23        | 0.00322   | 0.639     | 0.284     | 0.175     |
| traffic light     | 128    | 14        | 0.00467   | 0.5       | 0.169     | 0.126     |
| stop sign         | 128    | 9         | 0.00177   | 0.778     | 0.4       | 0.224     |

**ObservaÃ§Ãµes sobre os resultados:**
* As mÃ©tricas de mAP (mAP50 e mAP50-95) sÃ£o baixas, indicando que o modelo tem dificuldades em fazer detecÃ§Ãµes precisas e bem localizadas.
* A precisÃ£o (P) Ã© extremamente baixa para ambas as classes, sugerindo uma alta taxa de falsos positivos (o modelo detecta muitos objetos que nÃ£o sÃ£o as classes alvo).
* O recall (R) Ã© razoÃ¡vel, especialmente para 'stop sign', o que significa que o modelo consegue encontrar uma boa parte dos objetos reais, mas nÃ£o os localiza com precisÃ£o ou com muitos falsos positivos.
* **A principal causa para esses resultados iniciais Ã© o tamanho reduzido do dataset utilizado para treinamento e validaÃ§Ã£o.**

## ğŸ”® Melhorias Futuras

Para aprimorar o desempenho do modelo, as seguintes aÃ§Ãµes sÃ£o recomendadas:

* **ExpansÃ£o do Dataset:** Aumentar significativamente o volume e a diversidade de imagens com semÃ¡foros e placas de pare, anotadas com alta qualidade. Utilizar datasets maiores ou coletar e anotar dados personalizados.
* **Mais Ã‰pocas de Treinamento:** Com um dataset maior, pode ser benÃ©fico treinar por mais Ã©pocas.
* **Aumento de Dados (Data Augmentation):** Aplicar tÃ©cnicas de aumento de dados mais agressivas para variar o dataset existente.
* **Ajuste de HiperparÃ¢metros:** Experimentar diferentes configuraÃ§Ãµes de hiperparÃ¢metros para otimizar o treinamento.

## ğŸ¤ ContribuiÃ§Ãµes

ContribuiÃ§Ãµes sÃ£o bem-vindas! Se vocÃª tiver sugestÃµes, melhorias ou encontrar algum problema, sinta-se Ã  vontade para abrir uma issue ou enviar um pull request.

---

## ğŸ“§ Contato

*  **Daniel Lemos**
* **LinkedIn:** [https://www.linkedin.com/in/danielvlemos/]
* **Email:** [danielvlemos@gmail.com]

---
